import pandas as pd
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LinearRegression
# 分类特征和数值特征列表
categorical_features = ['Direction', 'District', 'Elevator', 'Layout', 'Region', 'Renovation']
num_features = ['Size', 'Year']
# 加载或定义训练好的模型、编码器和标准化器
# encoder = OneHotEncoder()  # 已训练好的编码器
# scaler = StandardScaler()  # 已训练好的标准化器
# model = LinearRegression()  # 已训练好的线性回归模型

def predict_price(input_data):
    # 将用户输入的数据转换为DataFrame
    input_df = pd.DataFrame([input_data])

    # 对分类特征进行独热编码
    encoded_input = encoder.transform(input_df[categorical_features])
    encoded_input_df = pd.DataFrame(encoded_input, columns=encoder.get_feature_names_out())

    # 合并编码后的数据和原始DataFrame
    input_df = pd.concat([input_df.reset_index(drop=True), encoded_input_df], axis=1)

    # 删除原始的分类特征列
    input_df.drop(columns=categorical_features, inplace=True)

    # 标准化数值特征
    input_df[num_features] = scaler.transform(input_df[num_features])

    # 使用训练好的模型预测房价
    return model.predict(input_df)[0]

# 示例用户输入数据
input_data = {
    'Direction': '南北',
    'District': '东单',
    'Elevator': '无电梯',
    'Floor': '6',
    'Layout': '2室1厅',
    'Region': '东城',
    'Renovation': '精装',
    'Size': 60,
    'Year': 1988
}


                                                              五个方法
1. pivot_table：透视表操作
方法： 使用pivot_table方法可以根据一个或多个键对数据进行透视，类似于Excel中的透视表功能。

示例代码： 创建一个透视表，计算不同产品在不同月份的销售额。
import pandas as pd

# 创建一个DataFrame
data = {
    'Month': ['Jan', 'Jan', 'Feb', 'Feb', 'Jan', 'Feb'],
    'Product': ['A', 'B', 'A', 'B', 'A', 'B'],
    'Sales': [100, 200, 150, 250, 120, 220]
}
df = pd.DataFrame(data)

# 创建透视表
pivot_df = df.pivot_table(index='Month', columns='Product', values='Sales', aggfunc='sum')
print(pivot_df)
输出
Product    A    B
Month            
Feb      150  250
Jan      220  200
2. cut：数据分箱操作
方法： 使用cut方法将连续的数值数据分成离散的区间（箱子）。

示例代码： 对一个数据列进行分箱操作，并计算每个箱子中的数据数量。
import pandas as pd

# 创建一个DataFrame
data = {
    'Value': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
}
df = pd.DataFrame(data)

# 数据分箱
bins = [0, 30, 60, 100]
labels = ['Low', 'Medium', 'High']
df['Bins'] = pd.cut(df['Value'], bins=bins, labels=labels, right=True)

# 计算每个箱子中的数据数量
bin_counts = df['Bins'].value_counts()
print(bin_counts)
输出
Low       3
Medium    4
High      3
Name: Bins, dtype: int64

3. applymap：应用函数到数据框的每个元素
方法： 使用applymap方法将函数应用到数据框的每个元素。

示例代码： 将一个数据框中的所有元素转换为小写。
import pandas as pd

# 创建一个DataFrame
data = {
    'A': ['Apple', 'Banana', 'Orange'],
    'B': ['Cat', 'Dog', 'Elephant']
}
df = pd.DataFrame(data)

# 应用函数到每个元素
df_lower = df.applymap(lambda x: x.lower())
print(df_lower)
输出
        A         B
0   apple       cat
1  banana       dog
2  orange  elephant
4. pd.to_datetime：日期时间转换
方法： 使用pd.to_datetime方法将字符串或数值转换为日期时间格式。

示例代码： 将一个包含日期字符串的列转换为日期时间格式，并提取出年份。
import pandas as pd

# 创建一个DataFrame
data = {
    'A': ['Apple', 'Banana', 'Orange'],
    'B': ['Cat', 'Dog', 'Elephant']
}
df = pd.DataFrame(data)

# 使用DataFrame.apply和Series.map来转换为小写
df_lower = df.apply(lambda x: x.map(lambda y: y.lower() if isinstance(y, str) else y))
print(df_lower)
输出
        Date  Year
0 2023-01-01  2023
1 2024-02-15  2024
2 2025-03-30  2025
5. stack 和 unstack：数据堆叠与解堆操作
方法： 使用stack方法将数据框的列“堆叠”为多层索引的行，使用unstack方法将多层索引的行“解堆”为列。

示例代码： 创建一个多层索引的数据框，并进行堆叠与解堆操作。
import pandas as pd

# 创建一个DataFrame
data = {
    'A': [1, 2, 3],
    'B': [4, 5, 6],
    'C': [7, 8, 9]
}
df = pd.DataFrame(data, index=['X', 'Y', 'Z'])

# 将列堆叠为多层索引的行
stacked_df = df.stack()
print(stacked_df)

# 解堆多层索引的行为列
unstacked_df = stacked_df.unstack()
print(unstacked_df)
输出
X  A    1
   B    4
   C    7
Y  A    2
   B    5
   C    8
Z  A    3
   B    6
   C    9
dtype: int64

   A  B  C
X  1  4  7
Y  2  5  8
Z  3  6  9
数据导入（Input）
Pandas 支持从多种数据源和格式中导入数据，主要包括但不限于：
文本文件：如 CSV、TSV 等文本格式文件。
Excel 文件：可以处理多个工作表、特定范围的数据等。
JSON 文件：适用于半结构化和非结构化数据。
SQL 数据库：通过 SQL 查询语言从关系型数据库中导入数据。
HDF5 文件：适合大数据集，支持高效的读写操作。
HTML 表格：从网页上抓取表格数据。
读取函数：主要使用 pd.read_csv()、pd.read_excel()、pd.read_json()、pd.read_sql()、pd.read_hdf() 等函数来读取不同格式的数据。
参数和选项：这些函数支持多种参数和选项，如文件路径、分隔符、编码方式、日期解析、缺失值处理等，使得用户可以根据具体需求进行灵活配置。
灵活性：Pandas 可以处理大多数常见的数据导入需求，而且通过参数配置和定制，可以处理一些复杂的数据导入场景，如处理大文件、跳过或处理异常行等。
数据导出（Output）
Pandas 支持将处理过的数据导出为多种格式，便于与其他工具和用户分享和使用，包括但不限于：
文本文件：如 CSV、TSV 等文本格式文件。
Excel 文件：支持多个工作表、指定格式、数据范围等。
JSON 文件：可以导出为 JSON 格式，便于Web应用程序和API使用。
SQL 数据库：通过 to_sql() 函数将DataFrame中的数据写入关系型数据库表格。
HDF5 文件：支持高效的大数据集存储和读取。
HTML 表格：可以生成HTML格式的表格，方便网页显示。
写出函数：主要使用 DataFrame.to_csv()、DataFrame.to_excel()、DataFrame.to_json()、DataFrame.to_sql()、DataFrame.to_hdf() 等函数来将DataFrame中的数据写出到不同的目标。
参数和选项：类似于读取函数，写出函数也支持多种参数和选项，如文件路径、分隔符、编码方式、日期格式、缺失值处理等，以便用户根据需要进行定制。
性能和效率：Pandas 在处理数据导出时通常能够提供高效的性能，特别是对于大数据集和复杂格式的处理。
特点和优点
广泛的格式支持：Pandas 能够处理多种常见的数据格式，覆盖了从文本文件到数据库的各种数据源。
灵活性：读取和写出函数提供了丰富的参数选项，可以根据具体需求进行灵活配置和定制。
集成性：Pandas 可以与其他Python库和工具（如Matplotlib、NumPy等）很好地集成，支持数据处理、分析和可视化的完整工作流程。
效率：通常情况下，Pandas 在处理中等规模的数据时能够提供高效的性能。
缺点
内存消耗：对于非常大的数据集，Pandas 可能会占用较多的内存，需要适当的硬件资源支持。
不适合并行处理：在某些情况下，Pandas 的数据导入和导出操作可能不够并行化，导致在处理大规模数据时效率不高。
格式支持的局限性：虽然Pandas支持广泛的格式，但在处理某些特殊格式或要求特定定制的数据时，可能需要额外的处理或者借助其他工具。
